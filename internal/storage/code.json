[
  {
    "name": "loader.go",
    "content": "package storage\r\n\r\nimport (\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"strings\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/ontology-server/internal/logger\"\r\n\t\"github.com/chrlesur/ontology-server/internal/models\"\r\n\t\"github.com/chrlesur/ontology-server/internal/parser\"\r\n)\r\n\r\ntype OntologyLoader struct {\r\n\tstorage *MemoryStorage\r\n\tlogger  *logger.Logger\r\n}\r\n\r\nfunc NewOntologyLoader(storage *MemoryStorage, logger *logger.Logger) *OntologyLoader {\r\n\treturn \u0026OntologyLoader{\r\n\t\tstorage: storage,\r\n\t\tlogger:  logger,\r\n\t}\r\n}\r\n\r\n// LoadFiles charge une ontologie avec ses métadonnées et contextes\r\nfunc (l *OntologyLoader) LoadFiles(ontologyFile, contextFile, metadataFile string) error {\r\n\tl.logger.Info(fmt.Sprintf(\"Starting to load files: ontology=%s, context=%s, metadata=%s\", ontologyFile, contextFile, metadataFile))\r\n\r\n\t// Charger les métadonnées\r\n\tmetadata, err := l.loadMetadata(metadataFile)\r\n\tif err != nil {\r\n\t\tl.logger.Error(fmt.Sprintf(\"Failed to load metadata: %v\", err))\r\n\t\treturn fmt.Errorf(\"failed to load metadata: %w\", err)\r\n\t}\r\n\tl.logger.Info(\"Metadata loaded successfully\")\r\n\r\n\t// Charger l'ontologie\r\n\telements, relations, err := l.loadOntologyFile(ontologyFile)\r\n\tif err != nil {\r\n\t\tl.logger.Error(fmt.Sprintf(\"Failed to load ontology file: %v\", err))\r\n\t\treturn fmt.Errorf(\"failed to load ontology file: %w\", err)\r\n\t}\r\n\tl.logger.Info(fmt.Sprintf(\"Ontology loaded successfully: %d elements, %d relations\", len(elements), len(relations)))\r\n\r\n\t// Charger les contextes si présents\r\n\tif contextFile != \"\" {\r\n\t\tif err := l.enrichWithContexts(elements, contextFile, metadata.Files); err != nil {\r\n\t\t\tl.logger.Error(fmt.Sprintf(\"Failed to load contexts: %v\", err))\r\n\t\t\treturn fmt.Errorf(\"failed to load contexts: %w\", err)\r\n\t\t}\r\n\t\tl.logger.Info(\"Contexts loaded and associated successfully\")\r\n\t} else {\r\n\t\tl.logger.Info(\"No context file provided, skipping context loading\")\r\n\t}\r\n\r\n\t// Créer et stocker l'ontologie\r\n\tontology := \u0026models.Ontology{\r\n\t\tID:         fmt.Sprintf(\"onto_%d\", time.Now().UnixNano()),\r\n\t\tName:       metadata.OntologyFile,\r\n\t\tFilename:   ontologyFile,\r\n\t\tFormat:     filepath.Ext(ontologyFile)[1:],\r\n\t\tImportedAt: metadata.ProcessingDate,\r\n\t\tElements:   elements,\r\n\t\tRelations:  relations,\r\n\t\tSource:     metadata,\r\n\t}\r\n\r\n\tif err := l.storage.AddOntology(ontology); err != nil {\r\n\t\tl.logger.Error(fmt.Sprintf(\"Failed to add ontology to storage: %v\", err))\r\n\t\treturn fmt.Errorf(\"failed to add ontology to storage: %w\", err)\r\n\t}\r\n\tl.logger.Info(fmt.Sprintf(\"Ontology added to storage successfully with ID: %s\", ontology.ID))\r\n\r\n\treturn nil\r\n}\r\n\r\nfunc (l *OntologyLoader) loadMetadata(filename string) (*models.SourceMetadata, error) {\r\n\tl.logger.Info(fmt.Sprintf(\"Loading metadata from file: %s\", filename))\r\n\tdata, err := os.ReadFile(filename)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to read metadata file: %w\", err)\r\n\t}\r\n\r\n\tvar metadata models.SourceMetadata\r\n\tif err := json.Unmarshal(data, \u0026metadata); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to parse metadata JSON: %w\", err)\r\n\t}\r\n\r\n\tl.logger.Info(fmt.Sprintf(\"Metadata loaded successfully: OntologyFile=%s, ProcessingDate=%v\", metadata.OntologyFile, metadata.ProcessingDate))\r\n\treturn \u0026metadata, nil\r\n}\r\n\r\nfunc (l *OntologyLoader) loadOntologyFile(filename string) ([]*models.OntologyElement, []*models.Relation, error) {\r\n\tl.logger.Info(fmt.Sprintf(\"Loading ontology file: %s\", filename))\r\n\tswitch {\r\n\tcase strings.HasSuffix(filename, \".tsv\"):\r\n\t\telements, relations, err := parser.ParseTSV(filename)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, fmt.Errorf(\"failed to parse TSV: %w\", err)\r\n\t\t}\r\n\r\n\t\t// Convertir les slices en slices de pointeurs\r\n\t\telementPtrs := make([]*models.OntologyElement, len(elements))\r\n\t\tfor i := range elements {\r\n\t\t\telementPtrs[i] = \u0026elements[i]\r\n\t\t}\r\n\r\n\t\trelationPtrs := make([]*models.Relation, len(relations))\r\n\t\tfor i := range relations {\r\n\t\t\trelationPtrs[i] = \u0026relations[i]\r\n\t\t}\r\n\r\n\t\tl.logger.Info(fmt.Sprintf(\"TSV file parsed successfully: %d elements, %d relations\", len(elementPtrs), len(relationPtrs)))\r\n\t\treturn elementPtrs, relationPtrs, nil\r\n\r\n\tdefault:\r\n\t\treturn nil, nil, fmt.Errorf(\"unsupported file format: %s\", filepath.Ext(filename))\r\n\t}\r\n}\r\n\r\nfunc (l *OntologyLoader) enrichWithContexts(elements []*models.OntologyElement, contextFile string, fileInfos map[string]models.FileInfo) error {\r\n\tcontexts, err := parser.ParseJSON(contextFile)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to parse context file: %w\", err)\r\n\t}\r\n\tl.logger.Info(fmt.Sprintf(\"Parsed %d contexts from JSON file\", len(contexts)))\r\n\r\n\t// Créer un index pour un accès rapide aux contextes\r\n\tcontextIndex := make(map[string][]models.JSONContext)\r\n\tfor _, ctx := range contexts {\r\n\t\tnormalizedName := normalizeElementName(ctx.Element)\r\n\t\tcontextIndex[normalizedName] = append(contextIndex[normalizedName], ctx)\r\n\t}\r\n\r\n\tfor _, elem := range elements {\r\n\t\tnormalizedName := normalizeElementName(elem.Name)\r\n\t\tif ctxs, exists := contextIndex[normalizedName]; exists {\r\n\t\t\telem.Contexts = ctxs\r\n\t\t\tl.logger.Info(fmt.Sprintf(\"Associated %d contexts to element '%s'\", len(ctxs), elem.Name))\r\n\t\t} else {\r\n\t\t\tl.logger.Info(fmt.Sprintf(\"No contexts found for element '%s'\", elem.Name))\r\n\t\t}\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n",
    "size": 5234,
    "modTime": "2024-11-18T22:31:45.1436349+01:00",
    "path": "loader.go"
  },
  {
    "name": "memory.go",
    "content": "package storage\r\n\r\nimport (\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"regexp\"\r\n\t\"sort\"\r\n\t\"strings\"\r\n\t\"sync\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/ontology-server/internal/logger\"\r\n\t\"github.com/chrlesur/ontology-server/internal/models\"\r\n\t\"github.com/chrlesur/ontology-server/internal/parser\"\r\n)\r\n\r\nvar log *logger.Logger\r\n\r\nfunc init() {\r\n\tvar err error\r\n\tlog, err = logger.NewLogger(logger.INFO, \"logs\")\r\n\tif err != nil {\r\n\t\tpanic(fmt.Sprintf(\"Failed to initialize logger: %v\", err))\r\n\t}\r\n}\r\n\r\n// MemoryStorage represents an in-memory storage for ontologies\r\ntype MemoryStorage struct {\r\n\tontologies map[string]*models.Ontology\r\n\tmutex      sync.RWMutex\r\n}\r\n\r\n// NewMemoryStorage initializes and returns a new MemoryStorage\r\nfunc NewMemoryStorage() *MemoryStorage {\r\n\treturn \u0026MemoryStorage{\r\n\t\tontologies: make(map[string]*models.Ontology),\r\n\t}\r\n}\r\n\r\n// AddOntology adds a new ontology to the storage\r\nfunc (ms *MemoryStorage) AddOntology(ontology *models.Ontology) error {\r\n\tms.mutex.Lock()\r\n\tdefer ms.mutex.Unlock()\r\n\r\n\tif _, exists := ms.ontologies[ontology.ID]; exists {\r\n\t\treturn fmt.Errorf(\"ontology with ID %s already exists\", ontology.ID)\r\n\t}\r\n\r\n\tms.ontologies[ontology.ID] = ontology\r\n\tlog.Info(fmt.Sprintf(\"Added ontology with ID: %s\", ontology.ID))\r\n\treturn nil\r\n}\r\n\r\n// GetOntology retrieves an ontology by its ID\r\nfunc (ms *MemoryStorage) GetOntology(id string) (*models.Ontology, error) {\r\n\tms.mutex.RLock()\r\n\tdefer ms.mutex.RUnlock()\r\n\r\n\tontology, exists := ms.ontologies[id]\r\n\tif !exists {\r\n\t\treturn nil, fmt.Errorf(\"ontology with ID %s not found\", id)\r\n\t}\r\n\r\n\treturn ontology, nil\r\n}\r\n\r\n// UpdateOntology updates an existing ontology\r\nfunc (ms *MemoryStorage) UpdateOntology(ontology *models.Ontology) error {\r\n\tms.mutex.Lock()\r\n\tdefer ms.mutex.Unlock()\r\n\r\n\tif _, exists := ms.ontologies[ontology.ID]; !exists {\r\n\t\treturn fmt.Errorf(\"ontology with ID %s not found\", ontology.ID)\r\n\t}\r\n\r\n\tms.ontologies[ontology.ID] = ontology\r\n\tlog.Info(fmt.Sprintf(\"Updated ontology with ID: %s\", ontology.ID))\r\n\treturn nil\r\n}\r\n\r\n// DeleteOntology removes an ontology by its ID\r\nfunc (ms *MemoryStorage) DeleteOntology(id string) error {\r\n\tms.mutex.Lock()\r\n\tdefer ms.mutex.Unlock()\r\n\r\n\tif _, exists := ms.ontologies[id]; !exists {\r\n\t\treturn fmt.Errorf(\"ontology with ID %s not found\", id)\r\n\t}\r\n\r\n\tdelete(ms.ontologies, id)\r\n\tlog.Info(fmt.Sprintf(\"Deleted ontology with ID: %s\", id))\r\n\treturn nil\r\n}\r\n\r\n// ListOntologies returns a list of all stored ontologies\r\nfunc (ms *MemoryStorage) ListOntologies() []*models.Ontology {\r\n\tms.mutex.RLock()\r\n\tdefer ms.mutex.RUnlock()\r\n\r\n\tontologies := make([]*models.Ontology, 0, len(ms.ontologies))\r\n\tfor _, ontology := range ms.ontologies {\r\n\t\tontologies = append(ontologies, ontology)\r\n\t}\r\n\r\n\treturn ontologies\r\n}\r\n\r\nfunc (ms *MemoryStorage) GetElement(elementName string) (*models.OntologyElement, error) {\r\n\tms.mutex.RLock()\r\n\tdefer ms.mutex.RUnlock()\r\n\tfor _, ontology := range ms.ontologies {\r\n\t\tfor _, element := range ontology.Elements {\r\n\t\t\tif element.Name == elementName {\r\n\t\t\t\tlog.Info(fmt.Sprintf(\"Found element %s with %d contexts\", elementName, len(element.Contexts)))\r\n\t\t\t\treturn element, nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"element not found\")\r\n}\r\n\r\nfunc (ms *MemoryStorage) GetElementRelations(elementName string) ([]*models.Relation, error) {\r\n\tms.mutex.RLock()\r\n\tdefer ms.mutex.RUnlock()\r\n\r\n\tnormalizedName := normalizeElementName(elementName)\r\n\tlog.Info(fmt.Sprintf(\"Searching relations for normalized element name: %s\", normalizedName))\r\n\r\n\tvar relations []*models.Relation\r\n\tfor _, ontology := range ms.ontologies {\r\n\t\tfor _, relation := range ontology.Relations {\r\n\t\t\tif normalizeElementName(relation.Source) == normalizedName ||\r\n\t\t\t\tnormalizeElementName(relation.Target) == normalizedName {\r\n\t\t\t\trelations = append(relations, relation)\r\n\t\t\t\tlog.Info(fmt.Sprintf(\"Found relation: %s -\u003e %s -\u003e %s\",\r\n\t\t\t\t\trelation.Source, relation.Type, relation.Target))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\tif len(relations) == 0 {\r\n\t\treturn nil, fmt.Errorf(\"no relations found for element: %s\", elementName)\r\n\t}\r\n\r\n\treturn relations, nil\r\n}\r\n\r\n// LoadOntologyFromFile loads an ontology from files including metadata\r\nfunc (ms *MemoryStorage) LoadOntologyFromFile(ontologyFile, contextFile, metadataFile string) error {\r\n\tlog.Info(fmt.Sprintf(\"Loading ontology from file: %s with metadata: %s\", ontologyFile, metadataFile))\r\n\r\n\tmetadata, err := loadSourceMetadata(metadataFile)\r\n\tif err != nil {\r\n\t\tlog.Error(fmt.Sprintf(\"Error loading metadata: %v\", err))\r\n\t\treturn fmt.Errorf(\"error loading metadata: %w\", err)\r\n\t}\r\n\r\n\tvar elements []*models.OntologyElement\r\n\tvar relations []*models.Relation\r\n\r\n\tswitch {\r\n\tcase strings.HasSuffix(ontologyFile, \".tsv\"):\r\n\t\telementsSlice, relationsSlice, err := parser.ParseTSV(ontologyFile)\r\n\t\tif err != nil {\r\n\t\t\tlog.Error(fmt.Sprintf(\"Error parsing TSV file: %v\", err))\r\n\t\t\treturn fmt.Errorf(\"error parsing TSV file: %w\", err)\r\n\t\t}\r\n\t\telements = make([]*models.OntologyElement, len(elementsSlice))\r\n\t\trelations = make([]*models.Relation, len(relationsSlice))\r\n\t\tfor i := range elementsSlice {\r\n\t\t\telements[i] = \u0026elementsSlice[i]\r\n\t\t}\r\n\t\tfor i := range relationsSlice {\r\n\t\t\trelations[i] = \u0026relationsSlice[i]\r\n\t\t}\r\n\t// ... (autres cas pour OWL et RDF)\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"unsupported ontology file format\")\r\n\t}\r\n\r\n\tlog.Info(fmt.Sprintf(\"Loaded %d elements and %d relations from ontology file\", len(elements), len(relations)))\r\n\tlog.Info(fmt.Sprintf(\"Loaded elements: %v\", elements))\r\n\r\n\tnormalizedElements := make(map[string]*models.OntologyElement)\r\n\tfor _, elem := range elements {\r\n\t\tnormalizedName := normalizeElementName(elem.Name)\r\n\t\tlog.Info(fmt.Sprintf(\"Normalizing element name: %s -\u003e %s\", elem.Name, normalizedName))\r\n\t\tif existingElem, exists := normalizedElements[normalizedName]; exists {\r\n\t\t\texistingElem.Positions = append(existingElem.Positions, elem.Positions...)\r\n\t\t\tif len(elem.Description) \u003e len(existingElem.Description) {\r\n\t\t\t\texistingElem.Description = elem.Description\r\n\t\t\t}\r\n\t\t\tcombinedTypes := existingElem.Type + \"/\" + elem.Type\r\n\t\t\texistingElem.Type = deduplicateTypes(combinedTypes)\r\n\t\t} else {\r\n\t\t\telem.Type = deduplicateTypes(elem.Type)\r\n\t\t\tnormalizedElements[normalizedName] = elem\r\n\t\t\telem.OriginalName = elem.Name\r\n\t\t\telem.Name = normalizedName\r\n\t\t}\r\n\t}\r\n\r\n\telements = make([]*models.OntologyElement, 0, len(normalizedElements))\r\n\tfor _, elem := range normalizedElements {\r\n\t\telements = append(elements, elem)\r\n\t}\r\n\r\n\tvar contexts []models.JSONContext\r\n\tif contextFile != \"\" {\r\n\t\tcontexts, err = parser.ParseJSON(contextFile)\r\n\t\tif err != nil {\r\n\t\t\tlog.Error(fmt.Sprintf(\"Error parsing context file: %v\", err))\r\n\t\t\treturn fmt.Errorf(\"error parsing context file: %w\", err)\r\n\t\t}\r\n\t\tlog.Info(fmt.Sprintf(\"Loaded %d contexts from JSON file\", len(contexts)))\r\n\t}\r\n\r\n\ttotalAssociations := 0\r\n\tfor _, elem := range elements {\r\n\t\tlog.Info(fmt.Sprintf(\"Processing element: %s with %d positions\", elem.Name, len(elem.Positions)))\r\n\t\tif elem.Name == \"Renaissance\" {\r\n\t\t\tlog.Info(fmt.Sprintf(\"Renaissance positions: %v\", elem.Positions))\r\n\t\t}\r\n\t\tcontextMap := make(map[int]models.JSONContext)\r\n\t\tnormalizedElemName := normalizeElementName(elem.Name)\r\n\t\tfor _, ctx := range contexts {\r\n\t\t\tif elementInContext(normalizedElemName, ctx) {\r\n\t\t\t\tlog.Info(fmt.Sprintf(\"Context match found for %s\", elem.Name))\r\n\t\t\t\tfor _, pos := range elem.Positions {\r\n\t\t\t\t\tlog.Info(fmt.Sprintf(\"Checking position %d (context range: %d-%d)\", pos, ctx.StartOffset, ctx.EndOffset))\r\n\t\t\t\t\tif pos \u003e= ctx.StartOffset \u0026\u0026 pos \u003c= ctx.EndOffset {\r\n\t\t\t\t\t\tif _, exists := contextMap[ctx.Position]; !exists {\r\n\t\t\t\t\t\t\tcontextMap[ctx.Position] = ctx\r\n\t\t\t\t\t\t\ttotalAssociations++\r\n\t\t\t\t\t\t\tlog.Info(fmt.Sprintf(\"Associated new context (position %d) to element %s\", ctx.Position, elem.Name))\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tbreak\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\telem.Contexts = make([]models.JSONContext, 0, len(contextMap))\r\n\t\tfor _, ctx := range contextMap {\r\n\t\t\telem.Contexts = append(elem.Contexts, ctx)\r\n\t\t}\r\n\t\tlog.Info(fmt.Sprintf(\"Element %s has %d unique contexts after association\", elem.Name, len(elem.Contexts)))\r\n\t}\r\n\r\n\tontology := \u0026models.Ontology{\r\n\t\tID:         fmt.Sprintf(\"onto_%d\", time.Now().UnixNano()),\r\n\t\tName:       metadata.OntologyFile,\r\n\t\tFilename:   ontologyFile,\r\n\t\tFormat:     filepath.Ext(ontologyFile)[1:],\r\n\t\tImportedAt: metadata.ProcessingDate,\r\n\t\tElements:   elements,\r\n\t\tRelations:  relations,\r\n\t\tSource:     metadata,\r\n\t}\r\n\r\n\tlog.Info(fmt.Sprintf(\"Created new ontology with ID: %s\", ontology.ID))\r\n\terr = ms.AddOntology(ontology)\r\n\tif err != nil {\r\n\t\tlog.Error(fmt.Sprintf(\"Error adding ontology to storage: %v\", err))\r\n\t\treturn fmt.Errorf(\"error adding ontology to storage: %w\", err)\r\n\t}\r\n\r\n\tfor _, fileInfo := range metadata.Files {\r\n\t\tif fileInfo.SourceFile == filepath.Base(ontologyFile) {\r\n\t\t\tontology.SHA256 = fileInfo.SHA256Hash\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\r\n\tlog.Info(\"Ontology successfully loaded and added to storage\")\r\n\treturn nil\r\n}\r\n\r\nfunc loadSourceMetadata(filename string) (*models.SourceMetadata, error) {\r\n\tdata, err := os.ReadFile(filename)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to read metadata file: %w\", err)\r\n\t}\r\n\r\n\tvar metadata models.SourceMetadata\r\n\tif err := json.Unmarshal(data, \u0026metadata); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to parse metadata JSON: %w\", err)\r\n\t}\r\n\r\n\treturn \u0026metadata, nil\r\n}\r\n\r\nfunc normalizeElementName(name string) string {\r\n\tparts := strings.SplitN(name, \"_\", 2)\r\n\tif len(parts) == 2 \u0026\u0026 (parts[0] == \"est\" || parts[0] == \"a\") {\r\n\t\treturn parts[0] + \" \" + strings.ReplaceAll(parts[1], \"_\", \" \")\r\n\t}\r\n\r\n\tname = strings.ReplaceAll(name, \"_\", \" \")\r\n\r\n\tprefixes := []string{\r\n\t\t\"l\", \"d\", \"j\", \"m\", \"t\", \"s\", \"c\", \"n\", \"qu\",\r\n\t\t\"jusqu\", \"lorsqu\", \"puisqu\", \"quoiqu\", \"quelqu\",\r\n\t}\r\n\r\n\tfor _, prefix := range prefixes {\r\n\t\tpattern := fmt.Sprintf(`\\b%s \\b`, prefix)\r\n\t\treplacement := fmt.Sprintf(\"%s'\", prefix)\r\n\t\tname = regexp.MustCompile(pattern).ReplaceAllString(name, replacement)\r\n\t}\r\n\r\n\tname = strings.ReplaceAll(name, \"aujourd hui\", \"aujourd'hui\")\r\n\tname = strings.Join(strings.Fields(name), \" \")\r\n\r\n\treturn name\r\n}\r\n\r\nfunc deduplicateTypes(types string) string {\r\n\ttypeSlice := strings.Split(types, \"/\")\r\n\ttypeMap := make(map[string]string)\r\n\tfor _, t := range typeSlice {\r\n\t\tt = strings.TrimSpace(t)\r\n\t\tnormalizedType := normalizeType(t)\r\n\t\tif existingType, exists := typeMap[normalizedType]; exists {\r\n\t\t\tif len(t) \u003e len(existingType) {\r\n\t\t\t\ttypeMap[normalizedType] = t\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\ttypeMap[normalizedType] = t\r\n\t\t}\r\n\t}\r\n\r\n\tvar uniqueTypes []string\r\n\tfor _, t := range typeMap {\r\n\t\tuniqueTypes = append(uniqueTypes, t)\r\n\t}\r\n\r\n\tsort.Strings(uniqueTypes)\r\n\treturn strings.Join(uniqueTypes, \"/\")\r\n}\r\n\r\nfunc normalizeType(t string) string {\r\n\tt = strings.ReplaceAll(t, \"_\", \" \")\r\n\tt = strings.Join(strings.Fields(t), \" \")\r\n\treturn strings.ToLower(t)\r\n}\r\n\r\n// Fonction helper pour vérifier si un élément est présent dans un contexte\r\nfunc elementInContext(elem string, ctx models.JSONContext) bool {\r\n\tlog.Info(fmt.Sprintf(\"Checking if element '%s' is in context of '%s'\", elem, ctx.Element))\r\n\telemLower := strings.ToLower(elem)\r\n\tcontextText := strings.ToLower(strings.Join(append(ctx.Before, ctx.Element), \" \") + \" \" + strings.Join(ctx.After, \" \"))\r\n\r\n\tlog.Info(fmt.Sprintf(\"Element: %s, Context: %s\", elemLower, contextText))\r\n\r\n\t// Vérification de la correspondance exacte\r\n\tif strings.Contains(contextText, elemLower) {\r\n\t\tlog.Info(fmt.Sprintf(\"Exact match found for '%s' in context\", elem))\r\n\t\treturn true\r\n\t}\r\n\r\n\t// Vérification avec les underscores remplacés par des espaces\r\n\telemWithoutUnderscore := strings.ReplaceAll(elemLower, \"_\", \" \")\r\n\tif strings.Contains(contextText, elemWithoutUnderscore) {\r\n\t\tlog.Info(fmt.Sprintf(\"Match found for '%s' without underscores in context\", elem))\r\n\t\treturn true\r\n\t}\r\n\r\n\t// Vérification des parties individuelles du nom de l'élément\r\n\telemParts := strings.FieldsFunc(elemLower, func(r rune) bool {\r\n\t\treturn r == '_' || r == ' '\r\n\t})\r\n\r\n\tmatchCount := 0\r\n\tfor _, part := range elemParts {\r\n\t\tif strings.Contains(contextText, part) {\r\n\t\t\tmatchCount++\r\n\t\t\tlog.Info(fmt.Sprintf(\"Partial match found for part '%s' of '%s' in context\", part, elem))\r\n\t\t}\r\n\t}\r\n\r\n\t// Si plus de la moitié des parties correspondent, considérez-le comme une correspondance\r\n\tif float64(matchCount)/float64(len(elemParts)) \u003e 0.5 {\r\n\t\tlog.Info(fmt.Sprintf(\"Sufficient partial matches found for '%s' in context\", elem))\r\n\t\treturn true\r\n\t}\r\n\r\n\t// Vérification spéciale pour les éléments contenant \"est\" ou \"a\"\r\n\tif strings.Contains(elemLower, \"est_\") || strings.Contains(elemLower, \"a_\") {\r\n\t\tparts := strings.SplitN(elemLower, \"_\", 2)\r\n\t\tif len(parts) == 2 \u0026\u0026 strings.Contains(contextText, parts[1]) {\r\n\t\t\tlog.Info(fmt.Sprintf(\"Special case match found for '%s' in context\", elem))\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\r\n\tlog.Info(fmt.Sprintf(\"No match found for '%s' in context\", elem))\r\n\treturn false\r\n}\r\n\r\nfunc (ms *MemoryStorage) GetElementContexts(elementName string) ([]models.JSONContext, error) {\r\n\tms.mutex.RLock()\r\n\tdefer ms.mutex.RUnlock()\r\n\r\n\tlog.Info(fmt.Sprintf(\"GetElementContext Called for: %s\", elementName))\r\n\tnormalizedName := normalizeElementName(elementName)\r\n\tlog.Info(fmt.Sprintf(\"Normalized name: %s\", normalizedName))\r\n\r\n\tfor _, ontology := range ms.ontologies {\r\n\t\tfor _, elem := range ontology.Elements {\r\n\t\t\tlog.Info(fmt.Sprintf(\"Checking element: %s (normalized: %s)\", elem.Name, normalizeElementName(elem.Name)))\r\n\t\t\tif normalizeElementName(elem.Name) == normalizedName {\r\n\t\t\t\tlog.Info(fmt.Sprintf(\"GetElementContext found for %s with %d contexts\", elem.Name, len(elem.Contexts)))\r\n\t\t\t\tif len(elem.Contexts) == 0 {\r\n\t\t\t\t\tlog.Warning(fmt.Sprintf(\"Element %s found but has no contexts\", elem.Name))\r\n\t\t\t\t}\r\n\t\t\t\tfor i, ctx := range elem.Contexts {\r\n\t\t\t\t\tlog.Info(fmt.Sprintf(\"Context %d for %s: Position=%d, Element=%s\", i, elem.Name, ctx.Position, ctx.Element))\r\n\t\t\t\t}\r\n\t\t\t\treturn elem.Contexts, nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\tlog.Warning(fmt.Sprintf(\"Element not found: %s\", elementName))\r\n\treturn nil, fmt.Errorf(\"element not found: %s\", elementName)\r\n}\r\n",
    "size": 14064,
    "modTime": "2024-11-18T22:08:45.6465013+01:00",
    "path": "memory.go"
  },
  {
    "name": "memory_test.go",
    "content": "package storage\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"testing\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/ontology-server/internal/models\"\r\n)\r\n\r\nfunc TestNewMemoryStorage(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\tif ms == nil {\r\n\t\tt.Error(\"NewMemoryStorage returned nil\")\r\n\t}\r\n\tif ms.ontologies == nil {\r\n\t\tt.Error(\"ontologies map is not initialized\")\r\n\t}\r\n}\r\n\r\nfunc TestAddOntology(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\tontology := \u0026models.Ontology{ID: \"test1\", Name: \"Test Ontology\"}\r\n\r\n\terr := ms.AddOntology(ontology)\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Failed to add ontology: %v\", err)\r\n\t}\r\n\r\n\t// Try to add the same ontology again\r\n\terr = ms.AddOntology(ontology)\r\n\tif err == nil {\r\n\t\tt.Error(\"Expected error when adding duplicate ontology, got nil\")\r\n\t}\r\n}\r\n\r\nfunc TestGetOntology(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\tontology := \u0026models.Ontology{ID: \"test1\", Name: \"Test Ontology\"}\r\n\tms.AddOntology(ontology)\r\n\r\n\tretrieved, err := ms.GetOntology(\"test1\")\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Failed to get ontology: %v\", err)\r\n\t}\r\n\tif retrieved.ID != ontology.ID || retrieved.Name != ontology.Name {\r\n\t\tt.Error(\"Retrieved ontology does not match the original\")\r\n\t}\r\n\r\n\t_, err = ms.GetOntology(\"nonexistent\")\r\n\tif err == nil {\r\n\t\tt.Error(\"Expected error when getting nonexistent ontology, got nil\")\r\n\t}\r\n}\r\n\r\nfunc TestUpdateOntology(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\tontology := \u0026models.Ontology{ID: \"test1\", Name: \"Test Ontology\"}\r\n\tms.AddOntology(ontology)\r\n\r\n\tupdatedOntology := \u0026models.Ontology{ID: \"test1\", Name: \"Updated Test Ontology\"}\r\n\terr := ms.UpdateOntology(updatedOntology)\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Failed to update ontology: %v\", err)\r\n\t}\r\n\r\n\tretrieved, _ := ms.GetOntology(\"test1\")\r\n\tif retrieved.Name != \"Updated Test Ontology\" {\r\n\t\tt.Error(\"Ontology was not updated correctly\")\r\n\t}\r\n\r\n\tnonexistentOntology := \u0026models.Ontology{ID: \"nonexistent\", Name: \"Nonexistent\"}\r\n\terr = ms.UpdateOntology(nonexistentOntology)\r\n\tif err == nil {\r\n\t\tt.Error(\"Expected error when updating nonexistent ontology, got nil\")\r\n\t}\r\n}\r\n\r\nfunc TestDeleteOntology(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\tontology := \u0026models.Ontology{ID: \"test1\", Name: \"Test Ontology\"}\r\n\tms.AddOntology(ontology)\r\n\r\n\terr := ms.DeleteOntology(\"test1\")\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Failed to delete ontology: %v\", err)\r\n\t}\r\n\r\n\t_, err = ms.GetOntology(\"test1\")\r\n\tif err == nil {\r\n\t\tt.Error(\"Expected error when getting deleted ontology, got nil\")\r\n\t}\r\n\r\n\terr = ms.DeleteOntology(\"nonexistent\")\r\n\tif err == nil {\r\n\t\tt.Error(\"Expected error when deleting nonexistent ontology, got nil\")\r\n\t}\r\n}\r\n\r\nfunc TestListOntologies(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\tontology1 := \u0026models.Ontology{ID: \"test1\", Name: \"Test Ontology 1\"}\r\n\tontology2 := \u0026models.Ontology{ID: \"test2\", Name: \"Test Ontology 2\"}\r\n\tms.AddOntology(ontology1)\r\n\tms.AddOntology(ontology2)\r\n\r\n\tontologies := ms.ListOntologies()\r\n\tif len(ontologies) != 2 {\r\n\t\tt.Errorf(\"Expected 2 ontologies, got %d\", len(ontologies))\r\n\t}\r\n\r\n\tfoundOntology1 := false\r\n\tfoundOntology2 := false\r\n\tfor _, o := range ontologies {\r\n\t\tif o.ID == \"test1\" {\r\n\t\t\tfoundOntology1 = true\r\n\t\t}\r\n\t\tif o.ID == \"test2\" {\r\n\t\t\tfoundOntology2 = true\r\n\t\t}\r\n\t}\r\n\r\n\tif !foundOntology1 || !foundOntology2 {\r\n\t\tt.Error(\"ListOntologies did not return all added ontologies\")\r\n\t}\r\n}\r\n\r\nfunc TestConcurrency(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\tconcurrentOperations := 1000\r\n\r\n\t// Concurrent additions\r\n\tfor i := 0; i \u003c concurrentOperations; i++ {\r\n\t\tgo func(id int) {\r\n\t\t\tontology := \u0026models.Ontology{ID: fmt.Sprintf(\"test%d\", id), Name: fmt.Sprintf(\"Test Ontology %d\", id)}\r\n\t\t\tms.AddOntology(ontology)\r\n\t\t}(i)\r\n\t}\r\n\r\n\ttime.Sleep(time.Second) // Give time for goroutines to complete\r\n\r\n\t// Verify all ontologies were added\r\n\tontologies := ms.ListOntologies()\r\n\tif len(ontologies) != concurrentOperations {\r\n\t\tt.Errorf(\"Expected %d ontologies, got %d\", concurrentOperations, len(ontologies))\r\n\t}\r\n\r\n\t// Concurrent reads and updates\r\n\tfor i := 0; i \u003c concurrentOperations; i++ {\r\n\t\tgo func(id int) {\r\n\t\t\tontologyID := fmt.Sprintf(\"test%d\", id)\r\n\t\t\tms.GetOntology(ontologyID)\r\n\t\t\tupdatedOntology := \u0026models.Ontology{ID: ontologyID, Name: fmt.Sprintf(\"Updated Test Ontology %d\", id)}\r\n\t\t\tms.UpdateOntology(updatedOntology)\r\n\t\t}(i)\r\n\t}\r\n\r\n\ttime.Sleep(time.Second) // Give time for goroutines to complete\r\n\r\n\t// Verify all ontologies were updated\r\n\tfor i := 0; i \u003c concurrentOperations; i++ {\r\n\t\tontology, _ := ms.GetOntology(fmt.Sprintf(\"test%d\", i))\r\n\t\tif ontology.Name != fmt.Sprintf(\"Updated Test Ontology %d\", i) {\r\n\t\t\tt.Errorf(\"Ontology %d was not updated correctly\", i)\r\n\t\t}\r\n\t}\r\n}\r\nfunc TestLoadOntologyWithMetadata(t *testing.T) {\r\n\tms := NewMemoryStorage()\r\n\r\n\t// Créer un fichier de métadonnées temporaire avec la nouvelle structure\r\n\tmetadataContent := `{\r\n        \"ontology_file\": \"test.tsv\",\r\n        \"processing_date\": \"2024-10-29T08:54:33.959Z\",\r\n        \"files\": {\r\n            \"file1\": {\r\n                \"id\": \"file1\",\r\n                \"source_file\": \"test.txt\",\r\n                \"directory\": \"/test/path\",\r\n                \"file_date\": \"2024-10-29T08:54:33.959Z\",\r\n                \"sha256_hash\": \"test-hash\"\r\n            }\r\n        }\r\n    }`\r\n\r\n\tmetadataFile := filepath.Join(t.TempDir(), \"metadata.json\")\r\n\tif err := os.WriteFile(metadataFile, []byte(metadataContent), 0644); err != nil {\r\n\t\tt.Fatalf(\"Failed to create test metadata file: %v\", err)\r\n\t}\r\n\r\n\t// Créer un fichier TSV minimal pour le test\r\n\ttsvContent := \"Element1\\tType1\\tDescription1\\t1,2,3\"\r\n\ttsvFile := filepath.Join(t.TempDir(), \"test.tsv\")\r\n\tif err := os.WriteFile(tsvFile, []byte(tsvContent), 0644); err != nil {\r\n\t\tt.Fatalf(\"Failed to create test TSV file: %v\", err)\r\n\t}\r\n\r\n\t// Test du chargement\r\n\terr := ms.LoadOntologyFromFile(tsvFile, \"\", metadataFile)\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Failed to load ontology with metadata: %v\", err)\r\n\t}\r\n\r\n\t// Vérifier que les ontologies sont chargées avec les métadonnées\r\n\tontologies := ms.ListOntologies()\r\n\tif len(ontologies) != 1 {\r\n\t\tt.Errorf(\"Expected 1 ontology, got %d\", len(ontologies))\r\n\t}\r\n\r\n\t// Vérifier les métadonnées\r\n\tontology := ontologies[0]\r\n\tif ontology.Source == nil {\r\n\t\tt.Error(\"Expected source metadata to be present\")\r\n\t} else {\r\n\t\tif ontology.Source.OntologyFile != \"test.tsv\" {\r\n\t\t\tt.Errorf(\"Expected ontology file 'test.tsv', got '%s'\", ontology.Source.OntologyFile)\r\n\t\t}\r\n\t\tif len(ontology.Source.Files) != 1 {\r\n\t\t\tt.Errorf(\"Expected 1 file in metadata, got %d\", len(ontology.Source.Files))\r\n\t\t}\r\n\t\tfileInfo, exists := ontology.Source.Files[\"file1\"]\r\n\t\tif !exists {\r\n\t\t\tt.Error(\"Expected file info for 'file1' to exist\")\r\n\t\t} else {\r\n\t\t\tif fileInfo.SourceFile != \"test.txt\" {\r\n\t\t\t\tt.Errorf(\"Expected source file 'test.txt', got '%s'\", fileInfo.SourceFile)\r\n\t\t\t}\r\n\t\t\tif fileInfo.SHA256Hash != \"test-hash\" {\r\n\t\t\t\tt.Errorf(\"Expected SHA256 hash 'test-hash', got '%s'\", fileInfo.SHA256Hash)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n",
    "size": 6915,
    "modTime": "2024-11-18T09:58:33.6182886+01:00",
    "path": "memory_test.go"
  }
]